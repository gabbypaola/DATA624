#creating copy of original data
simulated2 <- simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
order(-rfImp2)
rfImp2
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
View(simulated)
model3 <- cforest(y ~., data = simulated)
install.packages("party")
library(party)
model3 <- cforest(y ~., data = simulated)
varImp(model3)
order(-varImp(model3))
library(randomForest)
library(caret)
model1 <- randomForest(y ~ ., data = simulated, importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
order(-rfImp1)
rfImp1
order(-varimp(model3))
order(-varimp(model3, conditional = TRUE))
library(party)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
install.packages("Cubist")
library(Cubist)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
varImp(cubist_model)
order(-varImp(cubist_model))
library(gbm)
install.packages("gbm")
library(gbm)
model4 <- gbm(y ~., data = simulated, distribution = "gaussian")
order(-varImp(model4))
gbm_model <- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(gbm_model)
View(gbm_model)
gbm_model
gbm_model["var.levels"]
gbm_model["m"]
summary.gbm(gbm_model)
gbm_model[["fit"]]
library(gbm)
gbm_model <- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(gbm_model)
library(gbm)
set.seed(624)
gbm_model <- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(gbm_model)
library(Cubist)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
order(-varImp(cubist_model))
View(simulated)
set.seed(624)
X1 <- rep(1:2, each=100)
Y <- X1 + rnorm(200, mean=0, sd=4)
X2 <- rnorm(200, mean=0, sd=2)
simData <- data.frame(Y=Y, X1=X1, X2=X2)
View(simData)
simulated <- mlbench.friedman1(200, sd = 1)
View(simulated)
simulated[["y"]]
simulated[["x"]]
simulated <- cbind(simulated$x, simulated$y)
View(simulated)
simulated <- as.data.frame(simulated)
View(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
View(simulated)
set.seed(333) #ensure replicability
#specify features with different granularities
hd <- sample(0:100000, 1000, replace = T)
md <- sample(0:1000, 1000, replace = T)
ld <- sample(0:10, 1000, replace = T)
#create y as a combination of our features with the addition of a random term
y <- hd + md + ld + rnorm(200)
df <- data.frame(hd, md, ld, y) #merge features into df for RF
View(df)
simulated <- mlbench.friedman1(200, sd = 1)
View(simulated)
tensample <- replicate(10, rnorm(30, mean = 0, sd = 2))
View(tensample)
tensample <- replicate(2, rnorm(30, mean = 0, sd = 2))
View(tensample)
simulated <- mlbench.friedman1(200, sd = 1)
View(simulated)
sample_1sd <- replicate(2, rnorm(200, mean = 0, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 0, sd = 2))
sample_4sd <- replicate(2, rnorm(200, mean = 0, sd = 4))
View(sample_1sd)
sample_1sd <- replicate(2, rnorm(200, mean = 5, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 10, sd = 2))
sample_4sd <- replicate(2, rnorm(200, mean = 15, sd = 4))
sim_data = cbind(sample_1sd, sample_2sd, sample_4sd)
View(simData)
View(sim_data)
sample_1sd <- replicate(2, rnorm(200, mean = 10, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 20, sd = 2))
sample_4sd <- replicate(2, rnorm(200, mean = 40, sd = 4))
sim_data = cbind(sample_1sd, sample_2sd, sample_4sd)
View(sim_data)
sample_1sd <- replicate(2, rnorm(200, mean = 10, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 20, sd = 4))
sample_4sd <- replicate(2, rnorm(200, mean = 40, sd = 8))
sim_data = cbind(sample_1sd, sample_2sd, sample_4sd)
View(sim_data)
sample_1sd <- replicate(2, rnorm(200, mean = 10, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 20, sd = 4))
sample_4sd <- replicate(2, rnorm(200, mean = 40, sd = 8))
sim_data <- cbind(sample_1sd, sample_2sd, sample_4sd)
sim_data <- as.data.frame(sim_data)
colnames(simulated)[ncol(simulated)] <- "y"
sample_1sd <- replicate(2, rnorm(200, mean = 10, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 20, sd = 4))
sample_4sd <- replicate(2, rnorm(200, mean = 40, sd = 8))
sim_data <- cbind(sample_1sd, sample_2sd, sample_4sd)
sim_data <- as.data.frame(sim_data)
colnames(simu_data)[ncol(sim_data)] <- "y"
sample_1sd <- replicate(2, rnorm(200, mean = 10, sd = 1))
sample_2sd <- replicate(2, rnorm(200, mean = 20, sd = 4))
sample_4sd <- replicate(2, rnorm(200, mean = 40, sd = 8))
sim_data <- cbind(sample_1sd, sample_2sd, sample_4sd)
sim_data <- as.data.frame(sim_data)
colnames(sim_data)[ncol(sim_data)] <- "y"
View(sim_data)
â™£rep(1:2, each=100)
rep(1:2, each=100)
View(simData)
var(simData$X1)
var(simData$X2)
library(AppliedPredictiveModeling)
library(dplyr)
library(forecast)
library(ggplot2)
library(tidyr)
library(mice)
library(corrplot)
library(MASS)
library(earth)
library(RANN)
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
library(randomForest)
library(caret)
model1 <- randomForest(y ~ ., data = simulated, importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
order(-rfImp1)
rfImp1
#creating copy of original data
simulated2 <- simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
order(-rfImp2)
rfImp2
library(party)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
library(Cubist)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
order(-varImp(cubist_model))
library(gbm)
set.seed(624)
gbm_model <- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(gbm_model)
#used rnorm to create random data with different distributions
sample_2sd <- replicate(1, rnorm(200, mean = 20, sd = 2))
sample_4sd <- replicate(1, rnorm(200, mean = 40, sd = 4))
Y <-
sim_data <- cbind(sample_1sd, sample_2sd, sample_4sd)
#used rnorm to create random data with different distributions
sample_2sd <- replicate(1, rnorm(200, mean = 20, sd = 2))
sample_4sd <- replicate(1, rnorm(200, mean = 40, sd = 4))
sim_data <- cbind(sample_1sd, sample_2sd, sample_4sd)
#used rnorm to create random data with different distributions
sample_2sd <- replicate(1, rnorm(200, mean = 20, sd = 2))
sample_4sd <- replicate(1, rnorm(200, mean = 40, sd = 4))
sim_data <- cbind(sample_2sd, sample_4sd)
sim_data <- as.data.frame(sim_data)
colnames(sim_data)[ncol(sim_data)] <- "y"
var(sample_2sd)
var(sample_4sd)
#specify features with different granularities
hd <- sample(0:100000, 1000, replace = T)
md <- sample(0:1000, 1000, replace = T)
ld <- sample(0:10, 1000, replace = T)
var(hd)
var(hd)
var(md)
var(ld)
y <- hd + md + ld + rnorm(200)
df <- data.frame(hd, md, ld, y)
View(df)
#samples
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
y <- low + med + high + rnorm(250)
#samples
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
y <- low + medium + high + rnorm(250)
sim_data <- data.frame(low, med, high, y)
var(low)
var(medium)
var(high)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model)
varImp(diff_gran_model, scale=FALSE)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
library(AppliedPredictiveModeling)
library(dplyr)
library(forecast)
library(ggplot2)
library(tidyr)
library(mice)
library(corrplot)
library(MASS)
library(earth)
library(RANN)
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
library(randomForest)
library(caret)
model1 <- randomForest(y ~ ., data = simulated, importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
order(-rfImp1)
rfImp1
#creating copy of original data
simulated2 <- simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
order(-rfImp2)
rfImp2
library(party)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
library(Cubist)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
order(-varImp(cubist_model))
library(gbm)
set.seed(624)
gbm_model <- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(gbm_model)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
sim_data <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = sim_data, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
#impute using caret
imputed_data <- preProcess(ChemicalManufacturingProcess, "knnImpute")
full_data <- predict(imputed_data, ChemicalManufacturingProcess)
#find low values
low_values <- nearZeroVar(full_data)
#remove low frequency columns using baser df[row,columns]
chem_data <- full_data[,-low_values]
#split using caret
index_chem <- createDataPartition(chem_data$Yield , p=.8, list=F)
train_chem <-  chem_data[index_chem,]
test_chem <- chem_data[-index_chem,]
View(test_chem)
train_predictors <- train_chem[-c(1)]
test_predictors <-  test_chem[-c(1)]
View(test_predictors)
#fit the model
rf_model <- randomForest(train_predictors, train_chem$Yield, importance = TRUE, ntrees = 1000)
rf_model
rfPred <- predict(rf_model, newdata = test_predictors)
postResample(pred = rfPred, obs = test_chem$Yield)
gbm_model <- gbm.fit(train.x, train$Yield, distribution = "gaussian")
gbm_model <- gbm.fit(train_predictors, train_chem$Yield, distribution = "gaussian")
gbm_model
gbmPred <- predict(gbm_model, newdata = test_predictors)
postResample(pred = gbmPred, obs = test_chem$Yield)
cube_model <- cubist(train_predictors, train_chem$Yield)
cube_model
cubePred <- predict(cube_model, newdata = test_predictors)
postResample(pred = cubePred, obs = test_chem$Yield)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
#impute using caret
imputed_data <- preProcess(ChemicalManufacturingProcess, "knnImpute")
full_data <- predict(imputed_data, ChemicalManufacturingProcess)
#remove highly correlated vars
highly_correlated = findCorrelation(cor(full_data), 0.80)
full_data = full_data[, -highly_correlated]
#find low values
low_values <- nearZeroVar(full_data)
#remove low frequency columns using baser df[row,columns]
chem_data <- full_data[,-low_values]
#split using caret
index_chem <- createDataPartition(chem_data$Yield , p=.8, list=F)
train_chem <-  chem_data[index_chem,]
test_chem <- chem_data[-index_chem,]
train_predictors <- train_chem[-c(1)]
test_predictors <-  test_chem[-c(1)]
#fit the model
rf_model <- randomForest(train_predictors, train_chem$Yield, importance = TRUE, ntrees = 1000)
rf_model
rfPred <- predict(rf_model, newdata = test_predictors)
postResample(pred = rfPred, obs = test_chem$Yield)
gbm_model <- gbm.fit(train_predictors, train_chem$Yield, distribution = "gaussian")
gbm_model
gbmPred <- predict(gbm_model, newdata = test_predictors)
postResample(pred = gbmPred, obs = test_chem$Yield)
cube_model <- cubist(train_predictors, train_chem$Yield)
cube_model
cubePred <- predict(cube_model, newdata = test_predictors)
postResample(pred = cubePred, obs = test_chem$Yield)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
#impute using caret
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
full_data <- predict(imputed_data, ChemicalManufacturingProcess)
#remove highly correlated vars
#highly_correlated = findCorrelation(cor(full_data), 0.80)
#full_data = full_data[, -highly_correlated]
#find low values
#low_values <- nearZeroVar(full_data)
#remove low frequency columns using baser df[row,columns]
#chem_data <- full_data[,-low_values]
#split using caret
# index_chem <- createDataPartition(chem_data$Yield , p=.8, list=F)
#
# train_chem <-  chem_data[index_chem,]
# test_chem <- chem_data[-index_chem,]
index_chem <- createDataPartition(full_data$Yield , p=.8, list=F)
train_chem <-  full_data[index_chem,]
test_chem <- full_data[-index_chem,]
train_predictors <- train_chem[-c(1)]
test_predictors <-  test_chem[-c(1)]
#fit the model
rf_model <- randomForest(train_predictors, train_chem$Yield, importance = TRUE, ntrees = 1000)
rf_model
rfPred <- predict(rf_model, newdata = test_predictors)
postResample(pred = rfPred, obs = test_chem$Yield)
gbm_model <- gbm.fit(train_predictors, train_chem$Yield, distribution = "gaussian")
gbm_model
gbmPred <- predict(gbm_model, newdata = test_predictors)
postResample(pred = gbmPred, obs = test_chem$Yield)
cube_model <- cubist(train_predictors, train_chem$Yield)
cube_model
cubePred <- predict(cube_model, newdata = test_predictors)
postResample(pred = cubePred, obs = test_chem$Yield)
varImp(rf_model)
order(-varImp(rf_model))
imp_values <- varImp(rf_model)
View(imp_values)
plot(imp_values)
varImp(rf_model)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train)
library(rpart)
library(rpart)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train)
library(rpart)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train_chem)
#produce tree plot
rpart_tree2 <- as.party(rpart_tree)
install.packages("partykit")
library(rpart)
library(partykit)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train_chem)
#produce tree plot
rpart_tree2 <- as.party(rpart_tree)
plot(rpart_tree2)
library(rpart)
library(partykit)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train_chem)
#produce tree plot
rpart.plot(rpartTree)
install.packages("rpart.plot")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
#train single tree model
rpart_tree <- rpart(Yield ~., data = train_chem)
#produce tree plot
rpart.plot(rpartTree)
rpart.plot(rpart_tree)
plot(varImp(rf_model), top = 10)
head(varImp(rf_model))
order(-head(varImp(rf_model),10))
View(test_chem)
head(varImp(rf_model),10)
set.seed(624)
#fit the model
rf_model <- randomForest(train_predictors, train_chem$Yield, importance = TRUE, ntrees = 1000)
rf_model
rfPred <- predict(rf_model, newdata = test_predictors)
postResample(pred = rfPred, obs = test_chem$Yield)
library(readr)
library(dplyr)
library(forecast)
library(ggplot2)
library(tidyr)
library(mice)
library(corrplot)
library(MASS)
library(earth)
library(RANN)
setwd("~/CUNY SPS/DATA_624/DATA624/Project 2")
train <- read.csv(TrainingData.xlsx)
train <- read.csv("TrainingData.xlsx")
View(train)
train <- read.xlsx("TrainingData.xlsx")
library(openxlsx)
library(dplyr)
library(forecast)
library(ggplot2)
library(tidyr)
library(mice)
library(corrplot)
library(MASS)
library(earth)
library(RANN)
train <- read.xlsx("TrainingData.xlsx")
View(train)
test <- read.xlsx("TestData.xlsx")
View(test)
str(train)
glimpse(train)
glimpse(test)
summary(train)
table(is.na(train))
sapply(train, function(x) sum(is.na(x)))
train <- read.xlsx("TrainingData.xlsx")
glimpse(train)
sapply(train, function(x) sum(is.na(x)))
#label the datasets
train$Dataset <- "train"
test$Dataset <- "test"
#merge for cleaning
data <- rbind(train,test)
test <- read.xlsx("TestData.xlsx")
glimpse(test)
sapply(test, function(x) sum(is.na(x)))
