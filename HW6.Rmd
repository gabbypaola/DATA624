---
title: "DATA 624 | Predictive Analytics"
author: "Gabriella Martinez"
date: "3/14/2022"
output:
      html_document:
        toc: yes
        toc_float: yes
        theme: yeti
        highlight: kate
        font-family: "Arial"
        code_folding: hide
---

# Homework 6: ARIMA
## Instructions
Do exercises  9.1, 9.2, 9.3, 9.5, 9.6, 9.7, 9.8  in [Forecasting: Principles and Practice](https://otexts.com/fpp3/). Please submit both your Rpubs link as well as attach the .rmd file with your code.

## Packages
```{r message=FALSE, warning=FALSE, class.source = 'fold-show'}
library(fpp3)
library(latex2exp)
library(ggpubr)
```

## Exercises

### 9.1
**Figure [9.32](https://otexts.com/fpp3/arima-exercises.html#fig:wnacfplus) shows the ACFs for 36 random numbers, 360 random numbers and 1,000 random numbers.**

![](C:\Users\gabri\OneDrive\Documents\CUNY SPS\DATA_624\DATA624\HW6pic1.png)

**a. Explain the differences among these figures. Do they all indicate that the data are white noise?**  
The correlations in each figure are not significantly different from zero since the peaks for each figure are all within the dashed blue lines. Each autocorreltaion function figure above suggests they are all white noise.

**b. Why are the critical values at different distances from the mean of zero? Why are the autocorrelations different in each figure when they each refer to white noise?**  
The critical values are at different distances from the mean of zero becuase the length of time, $T$ values are different for each. The formula for the critical values is $\pm 2/\sqrt{T}$, so as T increases, the crtical value deceases. The autocorrelations are different in each figure because the $T$ value is increasing thus decreasing the critical value area from left to right.

### 9.2
**A classic example of a non-stationary series are stock prices. Plot the daily closing prices for Amazon stock (contained in `gafa_stock`), along with the ACF and PACF. Explain how each plot shows that the series is non-stationary and should be differenced.**  

```{r}
#filter for amazon
amzn <- gafa_stock %>% 
  filter(Symbol == "AMZN")

#plot the time series, acf, pacf
amzn %>% 
  gg_tsdisplay(Close, plot_type = 'partial') +
  labs(title= "Daily Closing Prices",
       subtitle= "Ticker: AMZN")
```

The Amazon Closing Price plot shows a changing levels, a general upward trend with no seasonality or cyclic behavior. Based on the ACF plot above, we see that there is no seasonal pattern with a small trailing negative trend towards the end. In the ACF plot we see the ACF slowly decreasing with very large, positive r values. 


Differencing can help stabilize the mean of the Google Closing Price time series by removing changes in the level, and therefore eliminating (or reducing) the trend.

```{r}
#plot the time series, acf, pacf
amzn %>% 
  gg_tsdisplay(difference(Close), plot_type = 'partial') +
  labs(title= "Differenced Daily Closing Prices",
       subtitle= "Ticker: AMZN")
```

The ACF plot of the differenced Amazon Closing price is not autocorrelation.


### 9.3
**For the following series, find an appropriate Box-Cox transformation and order of differencing in order to obtain stationary data.**

**a. Turkish GDP from `global_economy`.**  

```{r message=FALSE, warning=FALSE}
#filter out for turkey
turkey <- global_economy %>% 
  filter(Country=='Turkey') %>% 
  select(Country, GDP)

#find lambda value
lambda <- turkey %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)

#find ndiffs 
turkey  %>%
  mutate(GDP = box_cox(GDP, lambda)) %>%
  features(GDP, unitroot_ndiffs)
```

For the Turkish GDP from `global_economy`, we find an appropriate Box-Cox transformation with a lambda of approximately 0.16. With respect to the differencing, using the `features` function we find the number of differences in order to obtain stationary data as one difference. 


**b. Accommodation takings in the state of Tasmania from `aus_accommodation`.**  

```{r message=FALSE, warning=FALSE}
#filter for tasmania
tasmania <- aus_accommodation %>% 
  filter(State == 'Tasmania')  %>%
  select(State, Takings)

#find lambda value
lambda_tasmania <- tasmania %>%
  features(Takings, features = guerrero) %>%
  pull(lambda_guerrero)

#get ndiffs
tasmania %>%
  mutate(Takings = box_cox(Takings, lambda_tasmania)) %>%
  features(Takings, unitroot_ndiffs) 
```

For the Accommodation takings in the state of Tasmania from `aus_accommodation`, we find an appropriate Box-Cox transformation with a lambda of approximately -0.05. With respect to the differencing, using the `features` function we find the number of differences in order to obtain stationary data as one difference.

**c. Monthly sales from `souvenirs`.**

```{r message=FALSE, warning=FALSE}
#find lambda
lambda_souvenirs <- souvenirs %>% 
  features(Sales, features = guerrero) %>%
  pull(lambda_guerrero)

#get ndiffs
souvenirs %>%
  mutate(Sales = box_cox(Sales, lambda_souvenirs)) %>%
  features(Sales, unitroot_ndiffs)
```

For the Monthly sales from `souvenirs`, we find an appropriate Box-Cox transformation with a lambda of approximately 0.002. With respect to the differencing, using the `features` function we find the number of differences in order to obtain stationary data as one difference.


### 9.5
**For your retail data (from Exercise 8 in Section 2.10), find the appropriate order of differencing (after transformation if necessary) to obtain stationary data.**

```{r}
set.seed(555)

myseries <- aus_retail %>%
  filter(`Series ID` == sample(aus_retail$`Series ID`,1))

myseries %>%
    gg_tsdisplay(Turnover, plot_type = 'partial', lag_max = 36) +
  labs(title= "Western Australia Turnover",
       subtitle="Industry: Department Stores", y = NULL)
```


```{r}
myseries %>% 
  transmute(
    `Turnover` = Turnover,
    `Log Turnover` = log(Turnover),
    `Annual Change Log Turnover` = difference(log(Turnover), 12),
        `Doubly differenced log Turnover` =
                     difference(difference(log(Turnover), 12), 1)
  )%>%
  pivot_longer(-Month, names_to="Type", values_to="Turnover") %>%
  mutate(
    Type = factor(Type, levels = c(
      "Turnover",
      "Log Turnover",
      "Annual Change Log Turnover",
      "Doubly differenced log Turnover"))
  ) %>%
  ggplot(aes(x = Month, y = Turnover)) +
  geom_line() +
  facet_grid(vars(Type), scales = "free_y") +
  labs(title= "Western Australia Turnover",
       subtitle="Industry: Department Stores", y = NULL)
```

A stationary series has no predictable patterns in the long term, with no trend and seasonality. There appears to be an increasing trend and strong seasonal pattern that increases in size as the level of the series increases. 

In order to stabilize the variance of the time series, a log transformation was taken. After the log was taken the variance was tamed, but the increasing trend is still an issue. The seasonally differenced data of the log transformation is reasonably stabilized, but is not completely stationary as such another round of differencing was performed.


### 9.6
**Simulate and plot some data from simple ARIMA models.**

**a. Use the following R code to generate data from an AR(1) model with $\phi_{1} = 0.6$ and $\sigma^2 = 1$. The process starts with $y_1=0$.**  

```{r message=FALSE, warning=FALSE, class.source = 'fold-show'}
#set.seed(1)

y <- numeric(100)
e <- rnorm(100)
for(i in 2:100)
  y[i] <- 0.6*y[i-1] + e[i]
sim <- tsibble(idx = seq_len(100), y = y, index = idx)

head(sim)
```

**b. Produce a time plot for the series. How does the plot change as you change $\phi_1$?**  
```{r}
sim %>% autoplot(y) +
  labs(title=  latex2exp::TeX(paste0("AR(1) model with $\\phi_{1}$ = 0.6, $\\sigma^2 = 1$, $y_1=0$")))
```


```{r}
#create the data
for(i in 2:100)
  y[i] <- 0.1*y[i-1] + e[i]
sim_2 <- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- -1.0*y[i-1] + e[i]
sim_3 <- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- 1.2*y[i-1] + e[i]
sim_4 <- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- .9*y[i-1] + e[i]
sim_5 <- tsibble(idx = seq_len(100), y = y, index = idx)

#generate the ggplot objects
plt1 <- sim_5 %>% autoplot(y) +
  labs(title=  latex2exp::TeX(paste0("AR(1) model with $\\phi_{1}$ = 0.9, $\\sigma^2 = 1$")))
plt2 <- sim_2 %>% autoplot(y) +
  labs(title=  latex2exp::TeX(paste0("AR(1) model with $\\phi_{1}$ = 0.1, $\\sigma^2 = 1$")))
plt3 <- sim_3 %>% autoplot(y) +
  labs(title=  latex2exp::TeX(paste0("AR(1) model with $\\phi_{1}$ = -1.0, $\\sigma^2 = 1$")))
plt4 <- sim_4 %>% autoplot(y) +
  labs(title=  latex2exp::TeX(paste0("AR(1) model with $\\phi_{1}$ = 1.2, $\\sigma^2 = 1$")))

#plot them all togther
ggarrange(plt1, plt2, plt3, plt4, ncol = 2, nrow = 2)
```

The wavelength of the time series changes as $\phi_{1}$ changes. As $\phi_{1}$ increases, the magnitude and wavelength increases and as $\phi_{1}$ decreases, so does the magnitude and wavelength.

**c. Write your own code to generate data from an MA(1) model with $\theta_{1} = 0.6$ and $\sigma^2=1$.**  

```{r message=FALSE, warning=FALSE, class.source = 'fold-show'}
for(i in 2:100)
  y[i] <- 0.6*e[i-1] + e[i] 

sim_ma <- tsibble(idx = seq_len(100), y = y, index = idx)
```

**d. Produce a time plot for the series. How does the plot change as you change $\theta_1$?**  
```{r}
sim_ma %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("MA(1) model with $\\theta_{1} = 0.6$, $\\sigma^2 = 1$, $y_1=0$")))
```


```{r}
#create the data
for(i in 2:100)
  y[i] <- 0*e[i-1] + e[i] 
sim_ma2 <- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- .9*e[i-1] + e[i] 
sim_ma3 <- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- 1.5*e[i-1] + e[i] 
sim_ma4<- tsibble(idx = seq_len(100), y = y, index = idx)

for(i in 2:100)
  y[i] <- -1.5*e[i-1] + e[i] 
sim_ma5<- tsibble(idx = seq_len(100), y = y, index = idx)

#create the ggplot objects
plt5 <- sim_ma2 %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("MA(1) model with $\\theta_{1} = 0$, $\\sigma^2 = 1$")))

plt6 <- sim_ma3 %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("MA(1) model with $\\theta_{1} = 0.9$, $\\sigma^2 = 1$")))

plt7 <- sim_ma4 %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("MA(1) model with $\\theta_{1} = 1.5$, $\\sigma^2 = 1$")))

plt8 <- sim_ma5 %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("MA(1) model with $\\theta_{1} = -1.5$, $\\sigma^2 = 1$")))

#plot them all togther
ggarrange(plt5, plt6, plt7, plt8, ncol = 2, nrow = 2)
```

**e. Generate data from an ARMA(1,1) model with $\phi_{1} = 0.6$, $\theta_1=0.6$, and $\sigma^2=1$.**  
```{r message=FALSE, warning=FALSE, class.source = 'fold-show'}
for(i in 2:100)
  y[i] <- 0.6*y[i-1] + 0.6*e[i-1] + e[i]

sim_arma <- tsibble(idx = seq_len(100), y = y, index = idx)
```

**f. Generate data from an AR(2) model with $\phi_1=-0.8$, $\phi_2=0.3$, and $\sigma^2=1$.  (Note that these parameters will give a non-stationary series.)**  
```{r message=FALSE, warning=FALSE, class.source = 'fold-show'}
for(i in 3:100)
  y[i] <- -0.8*y[i-1] + 0.3*y[i-2] + e[i]

sim_ar2 <- tsibble(idx = seq_len(100), y = y, index = idx)
```

**g. Graph the latter two series and compare them.**  
```{r}
plt9 <- sim_arma %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("ARMA(1,1) model with $\\phi_{1} = 0.6$, $\\theta_1=0.6$, and $\\sigma^2=1$")))

plt10 <- sim_ma5 %>% autoplot(y)+
  labs(title=  latex2exp::TeX(paste0("AR(2) model with $\\phi_1=-0.8$, $\\phi_2=0.3$, and $\\sigma^2=1$")))

ggarrange(plt9, plt10, ncol = 1, nrow = 2)
```


### 9.7
**Consider `aus_airpassengers`, the total number of passengers (in millions) from Australian air carriers for the period 1970-2011.**

```{r}
aus_airpassengers
```


**a. Use `ARIMA()` to find an appropriate ARIMA model. What model was selected. Check that the residuals look like white noise. Plot forecasts for the next 10 periods.**  

```{r}
#create model
fit <- aus_airpassengers %>%
  model(ARIMA(Passengers))

#find the fit
report(fit)
```

```{r}
#forecast 10 periods
fit %>% forecast(h=10) %>%
  autoplot(aus_airpassengers) +
  labs(y = "Millions of Passengers", 
       title = "Australian Air Passengers",
       subtitle = "10 Year Forecast")
```

```{r}
fit %>% gg_tsresiduals() + 
  labs(title = "Australian Air Passengers",
       subtitle = "10 Year Forecast")
```

Using the `ARIMA()` function, the model automatically selected for `aus_airpassengers` data the was an ARIMA(0,2,1). The output of the `gg_tsresiduals()` function confirms that the residuals are white noise.

**b. Write the model in terms of the backshift operator.**    

**c. Plot forecasts from an ARIMA(0,1,0) model with drift and compare these to part a.**   
```{r}
#ARIMA(0,1,0) 
fit2 <- aus_airpassengers %>%
  model(ARIMA(Passengers ~ pdq(0,1,0)))

#plot forecast
fit2 %>% forecast(h=10) %>%
  autoplot(aus_airpassengers)

#plot residuals
fit2 %>% gg_tsresiduals()
```


**d. Plot forecasts from an ARIMA(2,1,2) model with drift and compare these to parts a and c. Remove the constant and see what happens.**  

Running an `ARIMA(2,1,2)` on the `aus_airpassengers` results in a NULL model.

```{r}
#ARIMA(2,1,2) 
fit3 <- aus_airpassengers %>%
  model(ARIMA(Passengers ~ pdq(2,1,2)))

report(fit3)
```


**e. Plot forecasts from an ARIMA(0,2,1) model with a constant. What happens?**  
The automated model generated in 9.7.a is an `ARIMA(0,2,1)` model.

### 9.8
**For the United States GDP series (from `global_economy`):**

**if necessary, find a suitable Box-Cox transformation for the data;**

```{r}
us_gdp <- global_economy %>% 
  filter(Country=="United States")%>%
  select(Country, GDP)

lambda_gdp <- us_gdp %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)

us_gdp <- us_gdp %>%
  mutate(GDP = box_cox(GDP, lambda_gdp))
```

**fit a suitable ARIMA model to the transformed data using ARIMA();**
```{r}
fit <- us_gdp %>%
  model(
    arima = ARIMA(GDP, stepwise = FALSE, approx = FALSE)
  )
report(fit)
```

**try some other plausible models by experimenting with the orders chosen;**
```{r}
us_gdp %>%
  features(GDP, unitroot_ndiffs)
```


**choose what you think is the best model and check the residual diagnostics;**
**produce forecasts of your fitted model. Do the forecasts look reasonable?**
**compare the results with what you would obtain using ETS() (with no transformation).**




<!------- Below is for removing excessive space in Rmarkdown | HTML formatting -------->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
